"""
    GlobtimPostProcessing.jl

Label-aware post-processing framework for GlobTim experiment results.

This package provides adaptive analysis that automatically discovers and processes
experimental data based on tracking labels generated by globtimcore experiments.

# Main Features
- **Label-driven processing**: Reads `enabled_tracking` metadata from experiments
- **Adaptive statistics**: Computes only relevant statistics based on available data
- **Campaign aggregation**: Analyzes multiple experiments as coherent campaigns
- **Report generation**: Creates publication-ready analysis reports

# Typical Workflow
```julia
using GlobtimPostProcessing

# Single experiment
results = load_experiment_results("path/to/experiment")
stats = compute_statistics(results)
report = generate_report(results, stats)

# Multi-experiment campaign
campaign = load_campaign_results("path/to/campaign_directory")
campaign_stats = analyze_campaign(campaign)
```

Author: GlobTim Team
Created: October 2025
"""
module GlobtimPostProcessing

using JSON
using JSON3
using DataFrames
using Statistics
using LinearAlgebra
using Printf
using Dates
using CSV
using ProgressMeter
# using Globtim  # COMMENTED OUT: Removed dependency (only needed for ErrorCategorization)
using StatsBase
using Optim  # Critical point refinement
using ForwardDiff  # Gradient computation for validation

# Core functionality exports
export load_experiment_results, load_campaign_results
export compute_statistics, compute_statistics_for_label
export analyze_campaign, aggregate_campaign_statistics
export generate_report, generate_campaign_report
export save_report, generate_and_save_report, save_campaign_report
export ExperimentResult, CampaignResults

# Phase 2: Batch processing exports
export batch_analyze_campaign, load_campaign_with_progress
export aggregate_campaign_statistics_with_progress, batch_analyze_campaign_with_progress

# Phase 3: Error categorization exports (Issue #20) - COMMENTED OUT (requires Globtim)
# export categorize_campaign_errors, generate_error_summary
# export get_error_categories, get_severity_levels
# export categorize_error_message, extract_campaign_errors
# export filter_errors_by_category, filter_errors_by_severity
# export get_top_priority_errors, get_experiment_errors
# export calculate_error_rate, get_most_common_error_category
# export calculate_average_priority, analyze_errors_by_degree
# export format_error_report, format_error_table
# export get_error_dataframe, create_mock_campaign

# Parameter recovery exports (Issue #7)
export param_distance, load_experiment_config, load_critical_points_for_degree
export compute_parameter_recovery_stats, generate_parameter_recovery_table, has_ground_truth

# Quality diagnostics exports (Issue #7, Phase 3)
export load_quality_thresholds
export check_l2_quality
export detect_stagnation, StagnationResult
export check_objective_distribution_quality, ObjectiveDistributionResult

# Critical point classification exports
export classify_critical_point, classify_all_critical_points!
export count_classifications, find_distinct_local_minima
export get_classification_summary

# Landscape fidelity exports
export check_objective_proximity, estimate_basin_radius, check_hessian_basin
export assess_landscape_fidelity, batch_assess_fidelity
export ObjectiveProximityResult, HessianBasinResult, LandscapeFidelityResult

# Critical point refinement exports
export RefinementConfig, ode_refinement_config
export refine_experiment_results, refine_critical_points
export RefinedExperimentResult, RefinementResult
export load_raw_critical_points, save_refined_results, RawCriticalPointsData
export refine_critical_point, refine_critical_points_batch

# Gradient validation exports
export compute_gradient_norms, compute_gradient_norm
export validate_critical_points, add_gradient_validation!
export GradientValidationResult

# Define types first
"""
    ExperimentResult

Container for a single experiment's results and metadata.

# Fields
- `experiment_id::String`: Unique identifier for the experiment
- `metadata::Dict{String, Any}`: Experiment configuration and parameters
- `enabled_tracking::Vector{String}`: Labels of tracked quantities
- `tracking_capabilities::Vector{String}`: All possible tracking labels for this experiment
- `critical_points::Union{DataFrame, Nothing}`: Critical points DataFrame
- `performance_metrics::Union{Dict, Nothing}`: Timing and resource usage
- `tolerance_validation::Union{Dict, Nothing}`: Numerical validation results
- `source_path::String`: Path to experiment output directory
"""
struct ExperimentResult
    experiment_id::String
    metadata::Dict{String, Any}
    enabled_tracking::Vector{String}
    tracking_capabilities::Vector{String}
    critical_points::Union{DataFrame, Nothing}
    performance_metrics::Union{Dict, Nothing}
    tolerance_validation::Union{Dict, Nothing}
    source_path::String
end

"""
    CampaignResults

Container for multi-experiment campaign results.

# Fields
- `campaign_id::String`: Unique identifier for the campaign
- `experiments::Vector{ExperimentResult}`: Individual experiment results
- `campaign_metadata::Dict{String, Any}`: Campaign-level configuration
- `collection_timestamp::DateTime`: When results were collected
"""
struct CampaignResults
    campaign_id::String
    experiments::Vector{ExperimentResult}
    campaign_metadata::Dict{String, Any}
    collection_timestamp::DateTime
end

# Include submodules (after type definitions)
include("ResultsLoader.jl")
include("LabelDispatcher.jl")
include("StatisticsCompute.jl")
include("ReportGenerator.jl")
include("TableFormatting.jl")   # Terminal-friendly table formatting
include("CampaignAnalysis.jl")
include("BatchProcessing.jl")  # Phase 2: Batch processing functionality
include("ParameterRecovery.jl")  # Issue #7: Parameter recovery analysis
include("QualityDiagnostics.jl")  # Issue #7, Phase 3: Quality diagnostics
include("CriticalPointClassification.jl")  # Critical point classification based on Hessian eigenvalues
include("LandscapeFidelity.jl")  # Landscape fidelity: polynomial vs objective basin assessment
# include("ErrorCategorizationIntegration.jl")  # COMMENTED OUT: Requires Globtim dependency

# Critical point refinement (moved from globtimcore - 2025-11-22)
include("refinement/core_refinement.jl")  # Core refinement algorithms
include("refinement/config.jl")           # RefinementConfig struct
include("refinement/gradient_validation.jl")  # Gradient norm validation (before io.jl - defines GradientValidationResult)
include("refinement/io.jl")               # Load/save utilities
include("refinement/api.jl")              # High-level API

# NOTE: Plotting functionality has been moved to GlobtimPlots package
# To create visualizations, use:
#     using GlobtimPostProcessing
#     using GlobtimPlots
#     plots = create_experiment_plots(experiment_result)
#
# GlobtimPlots provides:
# - create_experiment_plots, create_campaign_comparison_plot, create_single_plot, save_plot
# - PlotBackend types: Interactive, Static
# - generate_experiment_labels
#
# This separation ensures GlobtimPostProcessing remains a pure data analysis package
# without heavy plotting dependencies.

end # module GlobtimPostProcessing
